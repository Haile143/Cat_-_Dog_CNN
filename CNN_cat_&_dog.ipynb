{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_cat_&_dog.ipynb",
      "provenance": [],
      "mount_file_id": "14Y8MFGId6Cmkwz9m3hRtP00qjcagze-w",
      "authorship_tag": "ABX9TyMcPWtIPsTCdjnmdPNfmbjq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haile143/Cat_-_Dog_CNN/blob/main/CNN_cat_%26_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Tensorflow"
      ],
      "metadata": {
        "id": "ZXr1n0JGtJOM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1lN0w5rg0II"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "mMaoJoF3hiXS",
        "outputId": "cc5fdce4-506a-4cc9-abb8-3271ac693416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "bRGkYZIlhyiJ",
        "outputId": "a0ed1672-0766-4ec9-96b0-7fe119c1abb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Image Data\n",
        "\n",
        "### Train set"
      ],
      "metadata": {
        "id": "-OtZtkZetWm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Image Classification (Cats vs Dogs)/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXo_kijTjHZj",
        "outputId": "4faee42a-f932-4124-a08f-24977ecc5aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set"
      ],
      "metadata": {
        "id": "AoO54Pjatf74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_set=test_datagen.flow_from_directory('/content/drive/MyDrive/Image Classification (Cats vs Dogs)/test_set',\n",
        "                                          target_size =(64,64),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv974WDtJNrK",
        "outputId": "a5fb73fc-bf7d-4381-e5cf-8a5b7f7bfb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating CNN Model"
      ],
      "metadata": {
        "id": "-dWb-RAUtipK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn= tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "2FMiLR6nkU5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu',input_shape=[64,64,3]))"
      ],
      "metadata": {
        "id": "Bwe57rDUQeR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "metadata": {
        "id": "Q-SSMmKmSF_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "6musdvyXWY0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "zjke7cwqXl-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
      ],
      "metadata": {
        "id": "Ht4rR5_DXy7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "WGZZ5B4bYdFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Summary"
      ],
      "metadata": {
        "id": "W2hZs2Xptm8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY29SFxTYs4V",
        "outputId": "a6908691-7fd6-4dcf-ae9d-2c0eca1b84b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,217\n",
            "Trainable params: 813,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling and trainning our model.(25 EPOCHS)"
      ],
      "metadata": {
        "id": "mmta6XvXtsQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer ='adam',loss = 'binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "G_aqyp1VkwyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4aZNymilPUW",
        "outputId": "c60b94c7-b5d5-43a9-dbf4-da8e6108294d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "125/125 [==============================] - 571s 4s/step - loss: 0.7014 - accuracy: 0.5340 - val_loss: 0.6855 - val_accuracy: 0.5550\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 46s 367ms/step - loss: 0.6723 - accuracy: 0.5895 - val_loss: 0.6522 - val_accuracy: 0.6310\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 46s 371ms/step - loss: 0.6385 - accuracy: 0.6403 - val_loss: 0.6081 - val_accuracy: 0.6650\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 44s 355ms/step - loss: 0.6137 - accuracy: 0.6668 - val_loss: 0.5819 - val_accuracy: 0.7080\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 46s 365ms/step - loss: 0.5774 - accuracy: 0.7032 - val_loss: 0.5542 - val_accuracy: 0.7310\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 44s 348ms/step - loss: 0.5509 - accuracy: 0.7240 - val_loss: 0.5234 - val_accuracy: 0.7520\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 44s 351ms/step - loss: 0.5310 - accuracy: 0.7315 - val_loss: 0.4968 - val_accuracy: 0.7740\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 45s 360ms/step - loss: 0.5143 - accuracy: 0.7477 - val_loss: 0.5220 - val_accuracy: 0.7690\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 45s 360ms/step - loss: 0.4987 - accuracy: 0.7575 - val_loss: 0.4975 - val_accuracy: 0.7740\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 45s 356ms/step - loss: 0.4835 - accuracy: 0.7667 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 44s 355ms/step - loss: 0.4650 - accuracy: 0.7768 - val_loss: 0.4944 - val_accuracy: 0.7790\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 44s 354ms/step - loss: 0.4640 - accuracy: 0.7825 - val_loss: 0.4978 - val_accuracy: 0.7750\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 45s 356ms/step - loss: 0.4414 - accuracy: 0.7952 - val_loss: 0.4750 - val_accuracy: 0.7900\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 45s 356ms/step - loss: 0.4354 - accuracy: 0.7980 - val_loss: 0.4706 - val_accuracy: 0.7890\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 45s 362ms/step - loss: 0.4234 - accuracy: 0.8092 - val_loss: 0.4664 - val_accuracy: 0.7940\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 45s 357ms/step - loss: 0.4162 - accuracy: 0.8052 - val_loss: 0.4580 - val_accuracy: 0.8070\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 44s 354ms/step - loss: 0.4032 - accuracy: 0.8152 - val_loss: 0.4724 - val_accuracy: 0.7920\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 44s 355ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.4567 - val_accuracy: 0.7920\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 46s 366ms/step - loss: 0.3822 - accuracy: 0.8290 - val_loss: 0.4382 - val_accuracy: 0.8070\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 45s 358ms/step - loss: 0.3697 - accuracy: 0.8320 - val_loss: 0.4838 - val_accuracy: 0.7980\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 44s 356ms/step - loss: 0.3610 - accuracy: 0.8443 - val_loss: 0.4600 - val_accuracy: 0.7960\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 46s 368ms/step - loss: 0.3477 - accuracy: 0.8450 - val_loss: 0.4648 - val_accuracy: 0.8000\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 44s 353ms/step - loss: 0.3372 - accuracy: 0.8503 - val_loss: 0.4655 - val_accuracy: 0.8030\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 44s 354ms/step - loss: 0.3232 - accuracy: 0.8600 - val_loss: 0.4589 - val_accuracy: 0.8060\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 44s 355ms/step - loss: 0.3242 - accuracy: 0.8528 - val_loss: 0.4799 - val_accuracy: 0.7870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcc6c7d7f50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Accuracy by passing image through our model."
      ],
      "metadata": {
        "id": "lAyDeiiDt9A7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import classify_class_attrs\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/Image Classification (Cats vs Dogs)/single_prediction/cat_or_dog_1.jpg',target_size=(64,64))\n",
        "test_image =image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image, axis =0)\n",
        "result =cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0]==1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n"
      ],
      "metadata": {
        "id": "JHi7d6XQnTgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY6Y8vo4rEiE",
        "outputId": "9e57adbb-ce5c-4678-f3aa-bb5aa0f66976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ]
    }
  ]
}